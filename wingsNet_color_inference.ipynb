{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WingsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General OS and numerical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tnrange as trange\n",
    "import itertools\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import glob\n",
    "\n",
    "#Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "#Data management\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.kps import Keypoint, KeypointsOnImage\n",
    "\n",
    "#Image processing\n",
    "import cv2 as cv\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args/Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPUs\n",
    "print(\"CUDA availability = {}, number devices = {}\".format(torch.cuda.is_available(), torch.cuda.device_count()))\n",
    "for x in range(torch.cuda.device_count()):\n",
    "    print(x, torch.cuda.get_device_name(x))\n",
    "    \n",
    "#Flags\n",
    "TRAIN = True\n",
    "\n",
    "NUM_LAYERS = 16\n",
    "TRAIN_RATIO = 1.0\n",
    "RESIZE = (256, 256)\n",
    "\n",
    "#Training\n",
    "gpu_name = \"cuda:0\"\n",
    "# DEVICE = torch.device(\"cpu\") \n",
    "DEVICE = torch.device(gpu_name if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 16\n",
    "N_ITERS = 4\n",
    "\n",
    "z_scale = 843\n",
    "c_scale = 828\n",
    "\n",
    "IMG_SIZE = (2048, 1536)\n",
    "KPT_DIV = np.array([RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1],\n",
    "                    RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WingData(Dataset):\n",
    "    def __init__(self, list_paths, resize_dims=(512, 512), device='cpu'):\n",
    "        'Initialization'\n",
    "        super().__init__()\n",
    "        \n",
    "        self.list_paths = list_paths\n",
    "        self.device = device\n",
    "        self.resize_dims = resize_dims\n",
    "        \n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.Resize(resize_dims), \n",
    "            transforms.ToTensor()])\n",
    "        \n",
    "#         self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#             std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        self.seq = iaa.Sequential([iaa.Resize(resize_dims)])\n",
    "      \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        sample_path = self.list_paths[index]\n",
    "\n",
    "        if not os.path.isfile(sample_path):\n",
    "            print(\"{} is not a file/does not exist!\".format(sample_path))\n",
    "        # Load data and get label\n",
    "#         img = Image.open(sample_path)\n",
    "        image = cv.imread(sample_path)\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        image = cv.normalize(image, None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32FC3)\n",
    "        \n",
    "        image_aug = self.seq(image=image)\n",
    "        \n",
    "        input_tensor = ((torch.tensor(image_aug)).permute(2, 0, 1))\n",
    "        \n",
    "        return input_tensor, sample_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # DATA_PATH = \"/storage/data/wingNet/avi_data\"\n",
    "# data_files = pd.read_csv(DATA_PATH, header=None, delimiter=\"\\n\").values.flatten().tolist()\n",
    "\n",
    "# image_paths = []\n",
    "\n",
    "# for file in data_files:\n",
    "#     paths = glob.glob(file+'/*.tif')\n",
    "#     for path in paths:\n",
    "#         image_paths.append(path)\n",
    "    \n",
    "# data = WingData(image_paths, resize_dims=RESIZE, device=DEVICE)\n",
    "# train_size = int(len(data)*TRAIN_RATIO)\n",
    "# data_train, data_test = random_split(data, [train_size, len(data)-train_size])\n",
    "# dataloader = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# print(\"Using {} images in training, {} in validation.\".format(len(data_train), len(data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader_test = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# # dataloader_test = DataLoader(data_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# batch_iter = iter(dataloader_test)    \n",
    "# batch_test = batch_iter.__next__()\n",
    "\n",
    "# in_imgs = batch_test[0].numpy()\n",
    "# # keypoints = batch_test[1].numpy()*KPT_DIV\n",
    "# path = batch_test[1]\n",
    "\n",
    "# for i in range(0, BATCH_SIZE, 1):\n",
    "#     img_in = np.transpose(in_imgs[i], (1, 2, 0))\n",
    "#     plt.figure()\n",
    "#     plt.imshow(img_in)\n",
    "# #     plt.scatter(keypoints[i][::2], keypoints[i][1::2], c='r')\n",
    "# #     plt.scatter(keypoints[i][4], keypoints[i][5], c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"/storage/data/wing_models/wings_resnet34_color_256x256_good\", map_location=DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"/storage/data/wingNet/inference\"\n",
    "data_paths = np.array(pd.read_csv(CONFIG_PATH, header=None, delimiter=\"\\t\").values.tolist())\n",
    "for path in data_paths:\n",
    "    print(\"{}: {}\".format(path[0], path[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths(data_path):\n",
    "#     data_files = pd.read_csv(data_path, header=None, delimiter=\"\\n\").values.flatten().tolist()\n",
    "    image_paths = []\n",
    "    paths = glob.glob(data_path+'/*.tif')\n",
    "    paths.extend(glob.glob(data_path+'/*.bmp'))\n",
    "    paths.extend(glob.glob(data_path+'/*.png'))\n",
    "    paths.extend(glob.glob(data_path+'/*.jpg'))\n",
    "#     print(paths)\n",
    "    for path in paths:\n",
    "        image_paths.append(path)\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_forward(data):\n",
    "    dataloader = DataLoader(data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "#     print(\"Using {} images\".format(len(data)))\n",
    "    \n",
    "    batch_iter = iter(dataloader)    \n",
    "    batch_test = batch_iter.__next__()\n",
    "\n",
    "    input_tensor = batch_test[0].to(DEVICE, dtype=torch.float)\n",
    "    output_valid = model(input_tensor).cpu().detach().numpy()\n",
    "    output_valid = np.squeeze(output_valid)\n",
    "\n",
    "    output_valid = output_valid*KPT_DIV\n",
    "    \n",
    "    return input_tensor, output_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_horizontally = True\n",
    "grid_width = 15\n",
    "grid_height = len(data_paths)\n",
    "image_width = 5\n",
    "image_whitespace = 0.03\n",
    "if show_horizontally:\n",
    "    f, axarr = plt.subplots(grid_height, grid_width, \n",
    "                            figsize=(grid_width*image_width, \n",
    "                                     grid_height*image_width + image_whitespace*(grid_height)))\n",
    "    f.subplots_adjust(hspace=image_whitespace*2, wspace=image_whitespace)\n",
    "else:\n",
    "    f, axarr = plt.subplots(grid_width, grid_height, \n",
    "                            figsize=(grid_height*image_width + image_whitespace*(grid_height), \n",
    "                                     grid_width*image_width))\n",
    "    f.subplots_adjust(hspace=image_whitespace, wspace=image_whitespace)\n",
    "\n",
    "for paths, img_xpos in zip(data_paths, range(0, len(data_paths), 1)):\n",
    "    path = paths[1]\n",
    "    name = paths[0]\n",
    "    \n",
    "    data = WingData(get_image_paths(path), resize_dims=RESIZE, device=DEVICE)\n",
    "    train_size = int(len(data)*TRAIN_RATIO)\n",
    "    data_infer, data_test = random_split(data, [train_size, len(data)-train_size])\n",
    "    input_img, output_labels = pass_forward(data_infer)\n",
    "    \n",
    "    show_idx = 0\n",
    "    for i in range(show_idx, show_idx+grid_width, 1):\n",
    "        img_in = input_img[i].cpu().detach().numpy()\n",
    "        img_in = np.transpose(img_in, (1, 2, 0))\n",
    "        \n",
    "        if show_horizontally:\n",
    "            axarr[img_xpos, i].imshow(img_in)\n",
    "            axarr[img_xpos, i].scatter(output_labels[i][::2], output_labels[i][1::2], c='r', marker='x')\n",
    "            axarr[img_xpos, i].set_xticklabels([])\n",
    "            axarr[img_xpos, i].set_yticklabels([])\n",
    "            axarr[img_xpos, 0].set_ylabel(name, fontsize=40)\n",
    "        else:\n",
    "            axarr[i, img_xpos].imshow(img_in)\n",
    "            axarr[i, img_xpos].scatter(output_labels[i][::2], output_labels[i][1::2], c='r', marker='x')\n",
    "            axarr[i, img_xpos].set_xticklabels([])\n",
    "            axarr[i, img_xpos].set_yticklabels([])\n",
    "            axarr[0, img_xpos].set_title(name, fontsize=40)\n",
    "#         plt.imshow(img_in)\n",
    "#         plt.scatter(output_labels[i][::2], output_labels[i][1::2], c='r', marker='x')\n",
    "# for ax, col in zip(axarr[0], DATA_NAMES):\n",
    "#     ax.set_title(col)\n",
    "f.savefig('foo.png')\n",
    "f.savefig('foo.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader_test = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# # dataloader_test = DataLoader(data_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# batch_iter = iter(dataloader_test)    \n",
    "# batch_test = batch_iter.__next__()\n",
    "\n",
    "# input_tensor = batch_test[0].to(DEVICE, dtype=torch.float)\n",
    "# output_valid = model(input_tensor).cpu().detach().numpy()\n",
    "# output_valid = np.squeeze(output_valid)\n",
    "\n",
    "# print(\"Shape data = {}\".format(output_valid.shape))\n",
    "# output_valid = output_valid*KPT_DIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_idx = 0\n",
    "# for i in range(show_idx, show_idx+5, 1):\n",
    "#     img_in = input_tensor[i].cpu().detach().numpy()\n",
    "# #     gt_pts = output_valid[i][0]\n",
    "# #     print(\"Shape est={}, gt={}\".format(img_in.shape, img_in.shape))\n",
    "\n",
    "# #     f, axarr = plt.subplots(1,2)\n",
    "#     plt.figure()\n",
    "#     img_in = np.transpose(img_in, (1, 2, 0))\n",
    "#     plt.imshow(img_in)\n",
    "#     plt.scatter(output_valid[i][::2], output_valid[i][1::2], c='r', marker='x')\n",
    "# #     plt.scatter(input_valid[i][::2], input_valid[i][1::2], c='b')\n",
    "# #     plt.scatter(input_valid[i][8], input_valid[i][9], c='b')\n",
    "# #     print(input_valid[i])\n",
    "# #     axarr[0].imshow(img_in, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
