{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WingsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General OS and numerical\n",
    "# %matplotlib qt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tnrange as trange\n",
    "import itertools\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "\n",
    "#Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "#Data management\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.kps import Keypoint, KeypointsOnImage\n",
    "\n",
    "#Image processing\n",
    "import cv2 as cv\n",
    "from torchvision import transforms\n",
    "\n",
    "import random\n",
    "\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args/Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPUs\n",
    "print(\"CUDA availability = {}, number devices = {}\".format(torch.cuda.is_available(), torch.cuda.device_count()))\n",
    "for x in range(torch.cuda.device_count()):\n",
    "    print(x, torch.cuda.get_device_name(x))\n",
    "    \n",
    "#Flags\n",
    "TRAIN = True\n",
    "\n",
    "#Data\n",
    "# DATA_PATH = \"/storage/data_storage/wings/wings/all_wings\"\n",
    "DATA_PATH = \"/storage/data_storage/wings/wings/all_wings_ordered\" #good and consistant\n",
    "VALID_PATH = \"/storage/data_storage/wings/wings/all_wings_valid\"\n",
    "# DATA_PATH = \"/storage/data_storage/wings/wings/clem_wings.txt\" #good and consistant\n",
    "# DATA_PATH = \"/storage/data_storage/wings/wings/fiona_wings.txt\" #de-flipped and consistant\n",
    "# DATA_PATH = \"/storage/data_storage/wings/wings/fiona_wings_2.txt\" #de-flipped and consistant\n",
    "# DATA_PATH = \"/storage/data_storage/wings/wings/ness_wings_2.txt\" #de-flipped and consistant\n",
    "# DATA_PATH = \"/storage/data_storage/wings/wings/ness_wings_3.txt\" #de-flipped and consistant\n",
    "# DATA_PATH = \"/storage/data_storage/wings/wings/sandra_wings.txt\"  #good and consistant\n",
    "# DATA_PATH = \"/storage/data_storage/wings/wings/shaun_wings.txt\" #de-flipped and consistant\n",
    "# DATA_PATH = \"/storage/data_storage/wings/wings/tamblyn_wings.txt\" #de-flipped and consistant\n",
    "# DATA_PATH = \"/storage/data_storage/wings/wings/tamblyn_wings_2.txt\" #de-flipped and consistant\n",
    "# DATA_PATH = \"/storage/data_storage/wings/wings/teresa_wings.txt\" #de-flipped and consistant\n",
    "# DATA_PATH = \"/storage/data_storage/wings/wings/zoe_wings.txt\" #good and consistant\n",
    "\n",
    "# DATA_PATH = \"/storage/data_storage/wings/wings/ness_wings_4.txt\" # - bad - orders are not consistant\n",
    "# VALID_PATH = \"/storage/data_storage/wings/wings/ilaria_wings.txt\" #-bad - too many overlapping wings\n",
    "# DATA_PATH = \"/storage/data_storage/wings/wings/ness_wings.txt\" #-bad, broekn wings/overlapping\n",
    "PATH_PREFIX = \"/storage/data_storage/wings/\"\n",
    "TRAIN_RATIO = 1.0\n",
    "RESIZE = (256, 256)\n",
    "\n",
    "#Training\n",
    "gpu_name = \"cuda:0\"\n",
    "# DEVICE = torch.device(\"cpu\") \n",
    "DEVICE = torch.device(gpu_name if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "N_ITERS = 4\n",
    "\n",
    "z_scale = 843\n",
    "c_scale = 828\n",
    "\n",
    "IMG_SIZE = (2048, 1536)\n",
    "KPT_DIV = np.array([RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1],\n",
    "                    RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WingData(Dataset):\n",
    "    def __init__(self, list_paths, labels, resize_dims=(512, 512), augment=False, device='cpu'):\n",
    "        'Initialization'\n",
    "        super().__init__()\n",
    "        \n",
    "        self.list_paths = list_paths\n",
    "        self.labels = labels\n",
    "        self.device = device\n",
    "        self.resize_dims = resize_dims\n",
    "        self.augment = augment\n",
    "        \n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.Resize(resize_dims), \n",
    "            transforms.ToTensor()])\n",
    "        \n",
    "        self.seq_basic = iaa.Sequential([iaa.Resize(resize_dims)])\n",
    "        \n",
    "        self.seq1 = iaa.Sequential([\n",
    "            iaa.Affine(scale=(0.7, 1.0), mode='edge'), #'reflect'\n",
    "            iaa.Fliplr(0.5),\n",
    "            iaa.Flipud(0.5),\n",
    "            iaa.Resize(resize_dims)])\n",
    "              \n",
    "        self.seq2 = iaa.Sequential([\n",
    "            iaa.Affine(rotate=(-60, 60), scale=(0.7, 1.1), mode='edge'), #'reflect'\n",
    "            iaa.Crop(px=(0, 25)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "            iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "            iaa.Flipud(0.5),\n",
    "#             iaa.AddToHueAndSaturation((-20, 20), per_channel=True),\n",
    "#             iaa.Grayscale(),\n",
    "            iaa.Resize(resize_dims)])\n",
    "        \n",
    "    def add_noise(self, image, mean, var):\n",
    "        row, col, ch = image.shape\n",
    "        sigma = var**0.5\n",
    "        gauss = np.random.normal(mean, sigma, (row, col, ch))\n",
    "        gauss = gauss.reshape(row,col,ch)\n",
    "        noisy = image + gauss\n",
    "        return noisy\n",
    "        \n",
    "    def np_to_keypoints(self, np_kpoints, image_size):\n",
    "        np_kpoints = np_kpoints\n",
    "        kps = [\n",
    "            Keypoint(x=np_kpoints[0], y=image_size[0]-np_kpoints[1]),\n",
    "            Keypoint(x=np_kpoints[2], y=image_size[0]-np_kpoints[3]),\n",
    "            Keypoint(x=np_kpoints[4], y=image_size[0]-np_kpoints[5]),\n",
    "            Keypoint(x=np_kpoints[6], y=image_size[0]-np_kpoints[7]),\n",
    "            Keypoint(x=np_kpoints[8], y=image_size[0]-np_kpoints[9]),\n",
    "            Keypoint(x=np_kpoints[10], y=image_size[0]-np_kpoints[11]),\n",
    "            Keypoint(x=np_kpoints[12], y=image_size[0]-np_kpoints[13]),\n",
    "            Keypoint(x=np_kpoints[14], y=image_size[0]-np_kpoints[15]),\n",
    "        ]\n",
    "        return kps\n",
    "    \n",
    "    def point_out_of_range(self, kpts, image_size):\n",
    "        kpts_np = kpts.to_xy_array()\n",
    "        in_range_x = (kpts_np[:, 0] >= 0).all() and (kpts_np[:, 0] < RESIZE[0]).all()\n",
    "        in_range_y = (kpts_np[:, 1] >= 0).all() and (kpts_np[:, 1] < RESIZE[1]).all()\n",
    "        out_of_range = not in_range_x or not in_range_y\n",
    "        return out_of_range\n",
    "    \n",
    "    def apply_canny(self, img):\n",
    "        img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        img_gray = cv.normalize(img_gray, None, alpha=0, beta=255,\n",
    "                                norm_type=cv.NORM_MINMAX, dtype=cv.CV_8U)\n",
    "        img_gray = cv.GaussianBlur(img_gray, (3, 3), 0)\n",
    "        img_edges = cv.Canny(img_gray,10,50) \n",
    "        return img_edges\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        augment = True\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        sample_path = self.list_paths[index]\n",
    "\n",
    "        if not os.path.isfile(sample_path):\n",
    "            print(\"{} is not a file/does not exist!\".format(sample_path))\n",
    "        # Load data and get label\n",
    "#         img = Image.open(sample_path)\n",
    "        image = cv.imread(sample_path)\n",
    "        if image is None:\n",
    "            print(\"{} is not a valid image\".format(sample_path))       \n",
    "        image_size = image.shape\n",
    "            \n",
    "        kps = self.np_to_keypoints(self.labels[index].flatten(), image_size)\n",
    "        kpsoi = KeypointsOnImage(kps, shape=image.shape)\n",
    "#         image_aug, kpsoi_aug = self.seq(image=image, keypoints=kpsoi)\n",
    "        if not self.augment:\n",
    "            image_aug, kpsoi_aug = self.seq_basic(image=image, keypoints=kpsoi)\n",
    "            image_aug = cv.cvtColor(image_aug, cv.COLOR_BGR2RGB)\n",
    "            \n",
    "        if self.augment:\n",
    "            image_aug, kpsoi_aug = self.seq2(image=image, keypoints=kpsoi)\n",
    "            out_of_range = self.point_out_of_range(kpsoi_aug, image_size)\n",
    "            if out_of_range:\n",
    "                image_aug, kpsoi_aug = self.seq1(image=image, keypoints=kpsoi)\n",
    "#             H: 0-179, S: 0-255, V: 0-255 \n",
    "            image_aug = cv.cvtColor(image_aug, cv.COLOR_BGR2HSV)\n",
    "            add_hue = np.random.normal(0, 5)\n",
    "            add_sat = np.random.normal(0, 10)\n",
    "            add_val = np.random.normal(0, 0)\n",
    "#             print(\"h={}, s={}, v={}\".format(add_hue, add_sat, add_val))\n",
    "            image_aug[:, :, 0] = np.mod((image_aug[:, :, 0]+int(add_hue)), 180)\n",
    "            image_aug[:, :, 1] = np.clip((image_aug[:, :, 1]+int(add_sat)), 0, 254)\n",
    "            image_aug[:, :, 2] = np.clip((image_aug[:, :, 2]+int(add_val)), 0, 254)\n",
    "            \n",
    "            image_aug = cv.cvtColor(image_aug, cv.COLOR_HSV2RGB)\n",
    "\n",
    "            variance = random.uniform(0, 80)\n",
    "            image_aug = self.add_noise(image_aug, 0, variance)\n",
    "            \n",
    "        image_aug = cv.normalize(image_aug, None, alpha=0., beta=1., \n",
    "                                 norm_type=cv.NORM_MINMAX, dtype=cv.CV_32FC3)\n",
    "        img_edges = self.apply_canny(image_aug)\n",
    "        img_edges = cv.normalize(img_edges, None, alpha=0., beta=1., \n",
    "                                 norm_type=cv.NORM_MINMAX, dtype=cv.CV_32FC1)\n",
    "#         image_aug = image\n",
    "#         kpsoi_aug = kpsoi    \n",
    "        input_tensor = ((torch.tensor(image_aug)).permute(2, 0, 1))#self.normalize\n",
    "        edge_tensor = (torch.tensor(img_edges))[None, :]\n",
    "        output_tensor = torch.tensor(kpsoi_aug.to_xy_array().flatten()/KPT_DIV)\n",
    "\n",
    "        return input_tensor, edge_tensor, output_tensor, sample_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_orders = {\n",
    "    \"clem_wings\": [0,1,2,3,4,5,6,7],\n",
    "    \"fiona_wings\": [0,1,2,3,4,5,6,7],\n",
    "    \"fiona_wings_2\": [7,6,5,4,3,2,1,0],\n",
    "    \"ilaria_wings\": [0,1,2,3,4,5,6,7],\n",
    "    \"ness_wings\": [7,6,5,4,0,1,2,3],\n",
    "    \"ness_wings_2\": [4,5,6,7,3,2,1,0],\n",
    "    \"ness_wings_3\": [7,6,5,4,0,1,2,3],\n",
    "    \"ness_wings_4\": [7,6,5,4,3,2,1,0],\n",
    "    \"sandra_wings\": [0,1,2,3,4,5,6,7],\n",
    "    \"shaun_wings\": [0,1,2,3,4,5,6,7],\n",
    "    \"tamblyn_wings\": [6,7,4,5,3,2,1,0],\n",
    "    \"tamblyn_wings_2\": [0,1,2,3,7,6,5,4],\n",
    "    \"tamblyn_wings_3\": [0,1,2,3,7,6,5,4],\n",
    "    \"teresa_wings\": [7,6,5,4,3,2,1,0],\n",
    "    \"teresa_wings_2\": [0,1,2,3,4,5,6,7],\n",
    "    \"zoe_wings\": [0,1,2,3,4,5,6,7],\n",
    "    \"validation\": [7,6,5,4,3,2,1,0],\n",
    "    }\n",
    "\n",
    "def get_paths_from_tps_file(path_to_file):\n",
    "    # DATA_PATH = \"/storage/data/wingNet/landmarks\"\n",
    "    data_files = pd.read_csv(path_to_file, header=None, delimiter=\"\\n\").values.flatten().tolist()\n",
    "\n",
    "    image_paths = []\n",
    "    feature_coords = []\n",
    "    success_cnt = 0\n",
    "    fail_cnt = 0\n",
    "\n",
    "    for file in data_files:\n",
    "        file_path = PATH_PREFIX+file\n",
    "#         print(file_path)\n",
    "        folder_names = re.split('/|\\n', file_path)\n",
    "        point_order = point_orders[folder_names[5]]\n",
    "        f = open(file_path,'r')\n",
    "        cnt = 0\n",
    "\n",
    "        folder_path = os.path.dirname(file)\n",
    "        img_feature_coords = []\n",
    "        \n",
    "        warning_given = False\n",
    "        for line in f:\n",
    "            str_in = re.split('=|\\n', line)\n",
    "            if str_in[0]==\"SCALE\" or str_in[0]==\"LM\" or str_in[0]==\"ID\":\n",
    "                continue\n",
    "            elif str_in[0]==\"IMAGE\":\n",
    "                image_name = re.split('=|\\n', line)\n",
    "                if image_name[1][0]==\".\":\n",
    "                    image_name[1] = image_name[1][1:]\n",
    "#                     print(\"First character is dot: {}\".format(image_name[1]))\n",
    "                image_path = (PATH_PREFIX+folder_path+\"/\"+image_name[1]).strip()\n",
    "                if os.path.isfile(image_path) and len(img_feature_coords) == 8:\n",
    "                    image_paths.append(image_path)\n",
    "                    \n",
    "                    features = np.asarray(img_feature_coords, dtype=np.float32, order='C')\n",
    "                    permuted_features = []\n",
    "                    for i in range(0, len(features), 1):\n",
    "                        permuted_features.append(img_feature_coords[point_order[i]])\n",
    "                    permuted_features = np.asarray(permuted_features, dtype=np.float32, order='C')\n",
    "                    feature_coords.append(permuted_features)\n",
    "                    success_cnt+=1\n",
    "                else:\n",
    "                    if not warning_given:\n",
    "#                         print(\"==================================\")\n",
    "                        print(\"Issue with {} (has {} coordinates)\".format(\n",
    "                            image_path, len(img_feature_coords)))\n",
    "#                         print(img_feature_coords)\n",
    "#                         print(\"{}, {}\".format(image_name, line))\n",
    "                        warning_given = True\n",
    "                    \n",
    "                    fail_cnt+=1\n",
    "#                     print(img_feature_coords)\n",
    "                img_feature_coords = []\n",
    "            else:\n",
    "                coords_str = str.split(line)\n",
    "                img_feature_coords.append(coords_str)\n",
    "    print(\"Success/fail = {}/{}\".format(success_cnt, fail_cnt))\n",
    "    return image_paths, feature_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths, feature_coords = get_paths_from_tps_file(DATA_PATH)\n",
    "data = WingData(image_paths, feature_coords, resize_dims=RESIZE, augment=True, device=DEVICE)\n",
    "train_size = int(len(data)*TRAIN_RATIO)\n",
    "data_train, data_test = random_split(data, [train_size, len(data)-train_size])\n",
    "\n",
    "image_paths, feature_coords = get_paths_from_tps_file(VALID_PATH)\n",
    "data = WingData(image_paths, feature_coords, resize_dims=RESIZE, augment=False, device=DEVICE)\n",
    "train_size = int(len(data)*TRAIN_RATIO)\n",
    "data_valid, data_test = random_split(data, [train_size, len(data)-train_size])\n",
    "\n",
    "dataloader_valid = DataLoader(data_valid, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(\"Using {} images in training, {} in validation.\".format(len(data_train), len(data_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "dataloader_test = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# dataloader_test = DataLoader(data_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "cnt=0\n",
    "for batch_test in dataloader_test:\n",
    "    cnt+=1\n",
    "    if cnt < 0:\n",
    "        print(cnt)\n",
    "        continue\n",
    "    print(cnt)\n",
    "    images = batch_test[0]\n",
    "    edge_images = batch_test[1]\n",
    "    labels = batch_test[2]\n",
    "    filename = batch_test[3]\n",
    "    img = images[0].permute(1, 2, 0).numpy()\n",
    "    edge_img = edge_images[0][0].numpy()\n",
    "    f, axarr = plt.subplots(1,2)\n",
    "    \n",
    "    axarr[0].imshow(img)\n",
    "    axarr[1].imshow(edge_img)\n",
    "    break\n",
    "\n",
    "#     images = batch_test[0].to(DEVICE, dtype=torch.float)\n",
    "#     labels = batch_test[1].to(DEVICE, dtype=torch.float)\n",
    "#     filename = batch_test[2]\n",
    "    \n",
    "#     #Forward pass\n",
    "#     model.eval()\n",
    "#     NN_out = model(images)\n",
    "#     model.train()\n",
    "    \n",
    "#     input_valid = np.squeeze(labels.cpu().detach().numpy())*KPT_DIV\n",
    "#     output_valid = np.squeeze(NN_out.cpu().detach().numpy())*KPT_DIV\n",
    "#     img_in = images[0][0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "#     for i in range(0, 8, 1):\n",
    "#         plt.figure()\n",
    "#         plt.imshow(img_in, cmap='gray')\n",
    "#         plt.scatter(input_valid[2*i], input_valid[2*i+1], c='r')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_orientation(kpts_gt, kpts_est):\n",
    "    DIFF_THRESH = 0.5\n",
    "    for batch in range(0, len(kpts_gt), 1):\n",
    "        tmp = kpts_est[batch].clone()\n",
    "        \n",
    "        #no flip\n",
    "        min_loss = criterion(kpts_gt[batch], tmp)\n",
    "        original_loss = min_loss\n",
    "        min_op = \"identity\"\n",
    "        #horizontal flip\n",
    "        tmp[0::2] = 1.0-tmp[0::2]\n",
    "        loss = criterion(kpts_gt[batch], tmp)\n",
    "        if loss < (min_loss*DIFF_THRESH):\n",
    "            min_loss = loss\n",
    "            min_op = \"hor\"\n",
    "        #horizontal and vertical flip          \n",
    "        tmp[1::2] = 1.0-tmp[1::2]\n",
    "        loss = criterion(kpts_gt[batch], tmp)\n",
    "        if loss < (min_loss*DIFF_THRESH):\n",
    "            min_loss = loss\n",
    "            min_op = \"hor_ver\"\n",
    "        #vertical flip\n",
    "        tmp[0::2] = 1.0-tmp[0::2]\n",
    "        loss = criterion(kpts_gt[batch], tmp)\n",
    "        if loss < (min_loss*DIFF_THRESH):\n",
    "            min_loss = loss\n",
    "            min_op = \"ver\"\n",
    "                \n",
    "#         if min_op==\"hor\":\n",
    "# #             print(\"horizontal flip on {} - loss = {} v {}\".format(batch, min_loss, original_loss))\n",
    "#             kpts_est[batch, 0::2] = 1.0-kpts_est[batch, 0::2]\n",
    "#         elif min_op==\"hor_ver\":\n",
    "# #             print(\"double flip on {} - loss = {} v {}\".format(batch, min_loss, original_loss))\n",
    "#             kpts_est[batch, :] = 1.0-kpts_est[batch, :]\n",
    "#         elif  min_op==\"ver\":\n",
    "# #             print(\"vertical flip on {} - loss = {} v {}\".format(batch, min_loss, original_loss))\n",
    "#             kpts_est[batch, 1::2] = 1.0-kpts_est[batch, 1::2]\n",
    "\n",
    "    \n",
    "    return original_loss, min_loss, min_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import pylab as pl\n",
    "import time\n",
    "\n",
    "fix_automatically = False\n",
    "dataloader_test = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "cnt=0\n",
    "incorrect_label_order = []\n",
    "show_dp = 5\n",
    "colors = [0,1,2,3,4,5,6,7]\n",
    "leg_pts_x = np.arange(0, RESIZE[0], RESIZE[0]/8)\n",
    "leg_pts_y = np.full((8), RESIZE[0])\n",
    "corrupted = []\n",
    "for batch_test in dataloader_test:\n",
    "    cnt+=1\n",
    "    if cnt < 0:\n",
    "        if cnt%100==0:\n",
    "            print(cnt)\n",
    "        continue\n",
    "\n",
    "    images = batch_test[0].to(DEVICE, dtype=torch.float)\n",
    "    edge_images = batch_test[1].to(DEVICE, dtype=torch.float)\n",
    "    labels = batch_test[2].to(DEVICE, dtype=torch.float)\n",
    "    filename = batch_test[3]\n",
    "    \n",
    "    #Forward pass\n",
    "    model.eval()\n",
    "    NN_out = model(images)\n",
    "    model.train()\n",
    "    loss, min_loss, min_op = find_best_orientation(NN_out, labels)\n",
    "    print(\"{}: {:0.8f}, {:0.8f}, {}\".format(cnt, loss, min_loss, min_op))\n",
    "    if fix_automatically:\n",
    "        if cnt%250==0:\n",
    "            print(cnt)\n",
    "        if min_op == \"hor\":\n",
    "            print(\"{}: Flipping {} horizontally\".format(cnt, filename[0]))\n",
    "            img = cv.imread(filename[0])\n",
    "            img = cv.flip(img, 1)\n",
    "            cv.imwrite(filename[0], img)\n",
    "        if min_op == \"ver\":\n",
    "            print(\"{}: Flipping {} vertically\".format(cnt, filename[0]))\n",
    "            img = cv.imread(filename[0])\n",
    "            img = cv.flip(img, 0)\n",
    "            cv.imwrite(filename[0], img)\n",
    "        if min_op == \"hor_ver\":\n",
    "            print(\"{}: Flipping {} horizontally then vertically\".format(cnt, filename[0]))\n",
    "            img = cv.imread(filename[0])\n",
    "            img = cv.flip(img, 1)\n",
    "            img = cv.flip(img, 0)\n",
    "            cv.imwrite(filename[0], img)\n",
    "        if min_op is not \"identity\":\n",
    "            print(\"loss={:0.8f}, flip_loss={:0.8f}\".format(loss, min_loss))\n",
    "    else:\n",
    "#         if loss.item() > 0.01 or min_op is not \"identity\":\n",
    "#             print(\"{}: {} = {}\".format(cnt, filename[0], loss.item()))\n",
    "#             os.remove(filename[0])\n",
    "        print(\"{}: {} = {}\".format(cnt, filename, loss.item()))\n",
    "        if loss.item() > 0.01 or min_op is not \"identity\":\n",
    "    #         print(filename)\n",
    "            input_valid = np.squeeze(labels.cpu().detach().numpy())*KPT_DIV\n",
    "            output_valid = np.squeeze(NN_out.cpu().detach().numpy())*KPT_DIV\n",
    "            img_in = images[0][0].cpu().detach().numpy()\n",
    "            plt.figure()\n",
    "            plt.imshow(img_in, cmap='gray')\n",
    "            plt.scatter(output_valid[::2], output_valid[1::2], c='r', marker='x')\n",
    "    #         plt.scatter(input_valid[::2], input_valid[1::2], c='b')\n",
    "            plt.scatter(input_valid[::2], input_valid[1::2], c=colors, cmap='rainbow')\n",
    "            plt.scatter(leg_pts_x, leg_pts_y, c=colors, cmap='rainbow')\n",
    "\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "            input_txt = input(\"Continue...{}: loss={:0.8f}, flip_loss={:0.8f} path={} - suggested op={}\".format(\n",
    "                cnt, loss.item(), min_loss, filename[0], min_op))\n",
    "            if input_txt == \"v\":\n",
    "                img = cv.imread(filename[0])\n",
    "                img = cv.flip(img, 0)\n",
    "                cv.imwrite(filename[0], img)\n",
    "    #             plt.imshow(img_in, cmap='gray')\n",
    "            if input_txt == \"h\":\n",
    "                img = cv.imread(filename[0])\n",
    "                img = cv.flip(img, 1)\n",
    "                cv.imwrite(filename[0], img)\n",
    "            if input_txt == \"hv\" or input_txt == \"vh\":\n",
    "                img = cv.imread(filename[0])\n",
    "                img = cv.flip(img, 1)\n",
    "                img = cv.flip(img, 0)\n",
    "                cv.imwrite(filename[0], img)\n",
    "    #             plt.imshow(img_in, cmap='gray')\n",
    "            if input_txt == \"d\":\n",
    "                os.remove(filename[0])\n",
    "            if input_txt == \"i\":\n",
    "                incorrect_label_order.append(filename[0])\n",
    "\n",
    "            input(\"Action={}: loss={:0.8f} path={}\".format(input_txt, loss.item(), filename[0]))\n",
    "            plt.close()\n",
    "\n",
    "print(incorrect_label_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_linear = torch.nn.Linear(512, 16, bias=True)\n",
    "conv1 = torch.nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model = models.resnet34(pretrained=True)\n",
    "model.fc = output_linear\n",
    "model.conv1 = conv1\n",
    "\n",
    "# model = torch.load(\"/storage/data/models/wings_resnet34_color_256x256\", map_location=DEVICE)\n",
    "# model = torch.load(\"/storage/data/wing_models/wings_resnet34_gs_all_1mlp_very_good\", map_location=DEVICE)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.conv1.requires_grad = False\n",
    "# model.bn1.requires_grad = False\n",
    "\n",
    "# for param in model.layer1.parameters():\n",
    "#     param.requires_grad = False\n",
    "    \n",
    "# for param in model.layer2.parameters():\n",
    "#     param.requires_grad = False\n",
    "    \n",
    "# for param in model.layer3.parameters():\n",
    "#     param.requires_grad = False\n",
    "    \n",
    "# for param in model.parameters():\n",
    "#     print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "#Loss tracking\n",
    "loss_arr = []\n",
    "valid_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_loss(kpts_gt, kpts_est):\n",
    "    DIFF_THRESH = 0.1\n",
    "    for batch in range(0, len(kpts_gt), 1):\n",
    "        tmp = kpts_est[batch].clone()\n",
    "        \n",
    "        #no flip\n",
    "        min_loss = criterion(kpts_gt[batch], tmp)\n",
    "        original_loss = min_loss\n",
    "        min_op = \"identity\"\n",
    "        #horizontal flip\n",
    "        tmp[0::2] = 1.0-tmp[0::2]\n",
    "        loss = criterion(kpts_gt[batch], tmp)\n",
    "        if loss < min_loss*DIFF_THRESH:\n",
    "            min_loss = loss\n",
    "            min_op = \"hor\"\n",
    "        #horizontal and vertical flip          \n",
    "        tmp[1::2] = 1.0-tmp[1::2]\n",
    "        loss = criterion(kpts_gt[batch], tmp)\n",
    "        if loss < min_loss*DIFF_THRESH:\n",
    "            min_loss = loss\n",
    "            min_op = \"hor_ver\"\n",
    "        #vertical flip\n",
    "        tmp[0::2] = 1.0-tmp[0::2]\n",
    "        loss = criterion(kpts_gt[batch], tmp)\n",
    "        if loss < min_loss*DIFF_THRESH:\n",
    "            min_loss = loss\n",
    "            min_op = \"ver\"\n",
    "                \n",
    "        if min_op==\"hor\":\n",
    "#             print(\"horizontal flip on {} - loss = {} v {}\".format(batch, min_loss, original_loss))\n",
    "            kpts_est[batch, 0::2] = 1.0-kpts_est[batch, 0::2]\n",
    "        elif min_op==\"hor_ver\":\n",
    "#             print(\"double flip on {} - loss = {} v {}\".format(batch, min_loss, original_loss))\n",
    "            kpts_est[batch, :] = 1.0-kpts_est[batch, :]\n",
    "        elif  min_op==\"ver\":\n",
    "#             print(\"vertical flip on {} - loss = {} v {}\".format(batch, min_loss, original_loss))\n",
    "            kpts_est[batch, 1::2] = 1.0-kpts_est[batch, 1::2]\n",
    "\n",
    "    \n",
    "    return criterion(kpts_gt, kpts_est)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITERS = 30\n",
    "lr = 0.00002\n",
    "use_flip_loss = False\n",
    "use_flip_loss_valid = False\n",
    "epoch = 0\n",
    "loss_thresh = 1000.\n",
    "if TRAIN:\n",
    "    t = tqdm(range(N_ITERS), desc=\"epoch: \")\n",
    "    for i in t:\n",
    "        optim = torch.optim.Adam(model.parameters(), lr)\n",
    "        rec = True\n",
    "        inner = tqdm(dataloader, \"batch: \", leave=False)\n",
    "        ignored = []\n",
    "        \n",
    "        #Get a fresh validation batch\n",
    "        batch_iter_valid = iter(dataloader_valid)    \n",
    "        batch_valid = batch_iter_valid.__next__()\n",
    "        input_valid = batch_valid[0].to(DEVICE, dtype=torch.float)\n",
    "        edge_valid = batch_valid[1].to(DEVICE, dtype=torch.float)\n",
    "        label_valid = batch_valid[2].to(DEVICE, dtype=torch.float)\n",
    "        valid_tensor = torch.cat((input_valid, edge_valid), 1)\n",
    "                \n",
    "        for batch in inner:\n",
    "            optim.zero_grad()\n",
    "            images = batch[0].to(DEVICE, dtype=torch.float)\n",
    "            edge_images = batch[1].to(DEVICE, dtype=torch.float)\n",
    "            labels = batch[2].to(DEVICE, dtype=torch.float)\n",
    "            input_tensor = torch.cat((images, edge_images), 1)\n",
    "\n",
    "            #Forward pass\n",
    "            NN_out = model(input_tensor)\n",
    "            if use_flip_loss:\n",
    "#                 loss = invariant_mse_loss(NN_out, labels)\n",
    "                loss = flip_loss(NN_out, labels)\n",
    "            else:\n",
    "                loss = criterion(NN_out, labels)\n",
    "            \n",
    "            if loss.item() <= loss_thresh:  \n",
    "                #Training\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "\n",
    "                loss_arr.append(loss.item())\n",
    "\n",
    "                model.eval()\n",
    "                #Validation loss                \n",
    "                output_valid = model(valid_tensor)\n",
    "                if use_flip_loss_valid:\n",
    "                    loss_valid = flip_loss(output_valid, label_valid)\n",
    "                else:\n",
    "                    loss_valid = criterion(output_valid, label_valid)\n",
    "                valid_arr.append(loss_valid.item())\n",
    "\n",
    "                model.train()\n",
    "                inner.set_description(\"loss: {:.6f}, v_loss: {:.6f}\".format(loss.item(), loss_valid.item()))\n",
    "                #Set the first batch loss as the loss in the tqdm description\n",
    "                if rec==True:\n",
    "                    t.set_description(\"loss: {:.8f}, v_loss: {:.8f}\".format(loss.item(), loss_valid.item()))\n",
    "                    rec = False\n",
    "            else:\n",
    "                ignored.append(loss.item())\n",
    "                \n",
    "        print(\"epoch {}:lr={}, loss={}, v_loss={}\".format(epoch, lr, loss.item(), loss_valid.item()))\n",
    "        torch.save(model, \"/storage/data/models/wings_resnet34_color_canny\")\n",
    "        if epoch%4 == 0:\n",
    "            lr = lr*0.5\n",
    "        epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr)\n",
    "lim = 0.0005\n",
    "if TRAIN:\n",
    "    plt.ylim(0, lim)\n",
    "    plt.scatter(range(len(loss_arr[::1])), loss_arr[::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    plt.ylim(0, lim)\n",
    "    plt.scatter(range(len(valid_arr[::1])), valid_arr[::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr)\n",
    "lim = 0.00008\n",
    "if TRAIN:\n",
    "    plt.ylim(0, lim)\n",
    "    plt.scatter(range(len(loss_arr[::1])), loss_arr[::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = 0.0003\n",
    "if TRAIN:\n",
    "    plt.ylim(0, lim)\n",
    "    plt.scatter(range(len(valid_arr[::1])), valid_arr[::1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"/storage/data/models/wings_resnet34_color_canny_good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_test = DataLoader(data_valid, batch_size=BATCH_SIZE, shuffle=True)\n",
    "batch_iter = iter(dataloader_test)    \n",
    "batch_test = batch_iter.__next__()\n",
    "\n",
    "input_tensor = batch_test[0].to(DEVICE, dtype=torch.float)\n",
    "edge_tensor = batch_test[1].to(DEVICE, dtype=torch.float)\n",
    "gt_tensor = batch_test[2].numpy()\n",
    "validation_paths = batch_test[3]\n",
    "combined_tensor = torch.cat((input_tensor, edge_tensor), 1)\n",
    "\n",
    "model.eval()\n",
    "input_valid = (batch_test[2].cpu().detach().numpy())\n",
    "output_valid = model(combined_tensor).cpu().detach().numpy()\n",
    "output_valid = np.squeeze(output_valid)\n",
    "model.train()\n",
    "\n",
    "print(\"Shape data = {}, GT = {}\".format(input_valid.shape, output_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_valid = output_valid*KPT_DIV\n",
    "input_valid = input_valid*KPT_DIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "colors = [0,1,2,3,4,5,6,7]\n",
    "colormap = 'viridis'\n",
    "leg_pts_x = np.arange(10, RESIZE[0], RESIZE[0]/8)\n",
    "leg_pts_y = np.full((8), RESIZE[0]-10)\n",
    "strt_idx = 20\n",
    "# for i in range(strt_idx, strt_idx+5, 1):\n",
    "for i in range(0, BATCH_SIZE, 1):\n",
    "#     print(validation_paths[i])\n",
    "    img_in = input_tensor[i].cpu().detach().permute(1, 2, 0).numpy()\n",
    "#     print(\"Shape est={}, gt={}\".format(output_valid.shape, input_valid.shape))\n",
    "#     print(\"{}, {}\".format(np.max(img_in), np.min(img_in)))\n",
    "    plt.figure()\n",
    "    plt.imshow(img_in)\n",
    "#     plt.scatter(input_valid[i][::2], input_valid[i][1::2], c=colors, cmap=colormap)\n",
    "#     plt.scatter(leg_pts_x, leg_pts_y, c=colors, cmap=colormap)\n",
    "    plt.scatter(output_valid[i][::2], output_valid[i][1::2], c='r', marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
