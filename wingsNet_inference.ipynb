{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WingsNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General OS and numerical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tnrange as trange\n",
    "import itertools\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import glob\n",
    "\n",
    "#Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "#Data management\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.kps import Keypoint, KeypointsOnImage\n",
    "\n",
    "#Image processing\n",
    "import cv2 as cv\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args/Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPUs\n",
    "print(\"CUDA availability = {}, number devices = {}\".format(torch.cuda.is_available(), torch.cuda.device_count()))\n",
    "for x in range(torch.cuda.device_count()):\n",
    "    print(x, torch.cuda.get_device_name(x))\n",
    "    \n",
    "#Flags\n",
    "TRAIN = True\n",
    "\n",
    "#Data\n",
    "DATA_PATH = \"/storage/data/wingNet/avi_data\"\n",
    "# DATA_PATH = \"/storage/data/wingNet/teresa_data\"\n",
    "# DATA_PATH = \"/storage/data/wingNet/shawn_data\"\n",
    "NUM_LAYERS = 16\n",
    "TRAIN_RATIO = 1.0\n",
    "RESIZE = (256, 256)\n",
    "\n",
    "#Training\n",
    "gpu_name = \"cuda:0\"\n",
    "# DEVICE = torch.device(\"cpu\") \n",
    "DEVICE = torch.device(gpu_name if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "N_ITERS = 4\n",
    "\n",
    "z_scale = 843\n",
    "c_scale = 828\n",
    "\n",
    "IMG_SIZE = (2048, 1536)\n",
    "KPT_DIV = np.array([RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1],\n",
    "                    RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1], RESIZE[0], RESIZE[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WingData(Dataset):\n",
    "    def __init__(self, list_paths, resize_dims=(512, 512), device='cpu'):\n",
    "        'Initialization'\n",
    "        super().__init__()\n",
    "        \n",
    "        self.list_paths = list_paths\n",
    "        self.device = device\n",
    "        self.resize_dims = resize_dims\n",
    "        \n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.Resize(resize_dims), \n",
    "            transforms.ToTensor()])\n",
    "        \n",
    "#         self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#             std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        self.seq = iaa.Sequential([#iaa.Affine(translate_percent=(10, 10), rotate=(-45, 45), \n",
    "#                                               scale=(0.8, 1.2), mode='edge'), #'reflect'\n",
    "#                                    iaa.Crop(px=(0, 50)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "#                                    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "#                                    iaa.Flipud(0.5),\n",
    "#                                    iaa.AddToHueAndSaturation((-50, 50)),\n",
    "#                                    iaa.AdditiveGaussianNoise(0, 0.1),\n",
    "                                   iaa.Resize(resize_dims)])\n",
    "      \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        sample_path = self.list_paths[index]\n",
    "\n",
    "        if not os.path.isfile(sample_path):\n",
    "            print(\"{} is not a file/does not exist!\".format(sample_path))\n",
    "        # Load data and get label\n",
    "#         img = Image.open(sample_path)\n",
    "        image = cv.imread(sample_path)\n",
    "        image = cv.normalize(image, None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
    "        \n",
    "        image_aug = self.seq(image=image)\n",
    "    \n",
    "        input_tensor = ((torch.tensor(image_aug)).transpose(1,2).transpose(0,1))\n",
    "        \n",
    "        return input_tensor, sample_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = \"/storage/data/wingNet/avi_data\"\n",
    "data_files = pd.read_csv(DATA_PATH, header=None, delimiter=\"\\n\").values.flatten().tolist()\n",
    "\n",
    "image_paths = []\n",
    "\n",
    "for file in data_files:\n",
    "    paths = glob.glob(file+'/*.tif')\n",
    "    for path in paths:\n",
    "        image_paths.append(path)\n",
    "    \n",
    "data = WingData(image_paths, resize_dims=RESIZE, device=DEVICE)\n",
    "train_size = int(len(data)*TRAIN_RATIO)\n",
    "data_train, data_test = random_split(data, [train_size, len(data)-train_size])\n",
    "dataloader = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(\"Using {} images in training, {} in validation.\".format(len(data_train), len(data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# dataloader_test = DataLoader(data_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "batch_iter = iter(dataloader_test)    \n",
    "batch_test = batch_iter.__next__()\n",
    "\n",
    "in_imgs = batch_test[0].numpy()\n",
    "# keypoints = batch_test[1].numpy()*KPT_DIV\n",
    "path = batch_test[1]\n",
    "\n",
    "# print(\"Shape data = {}, GT = {}\".format(input_valid.shape, output_valid.shape))\n",
    "for i in range(0, BATCH_SIZE, 1):\n",
    "    img_in = in_imgs[i][0]\n",
    "    print(\"======== {} ========\".format(path[i]))\n",
    "#     print(\"Shape est={}, gt={}\".format(img_in.shape, img_in.shape))\n",
    "    plt.figure()\n",
    "    plt.imshow(img_in, cmap='gray')\n",
    "#     plt.scatter(keypoints[i][::2], keypoints[i][1::2], c='r')\n",
    "#     plt.scatter(keypoints[i][4], keypoints[i][5], c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_linear = torch.nn.Linear(2048, 16, bias=True)\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "model.fc = output_linear\n",
    "model = torch.load(\"/storage/data/models/wings_resnet50_gs\", map_location=DEVICE)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# dataloader_test = DataLoader(data_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "batch_iter = iter(dataloader_test)    \n",
    "batch_test = batch_iter.__next__()\n",
    "\n",
    "input_tensor = batch_test[0].to(DEVICE, dtype=torch.float)\n",
    "output_valid = model(input_tensor).cpu().detach().numpy()\n",
    "output_valid = np.squeeze(output_valid)\n",
    "\n",
    "print(\"Shape data = {}\".format(output_valid.shape))\n",
    "output_valid = output_valid*KPT_DIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, BATCH_SIZE, 1):\n",
    "    img_in = input_tensor[i][0].cpu().detach().numpy()\n",
    "#     gt_pts = output_valid[i][0]\n",
    "#     print(\"Shape est={}, gt={}\".format(img_in.shape, img_in.shape))\n",
    "\n",
    "#     f, axarr = plt.subplots(1,2)\n",
    "    plt.figure()\n",
    "    plt.imshow(img_in, cmap='gray')\n",
    "    plt.scatter(output_valid[i][::2], output_valid[i][1::2], c='r')\n",
    "#     plt.scatter(input_valid[i][::2], input_valid[i][1::2], c='b')\n",
    "#     plt.scatter(input_valid[i][8], input_valid[i][9], c='b')\n",
    "#     print(input_valid[i])\n",
    "#     axarr[0].imshow(img_in, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
